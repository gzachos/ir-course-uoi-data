
<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Learning classifier system - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"XpeTkgpAAEYAABoDvFAAAADP","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Learning_classifier_system","wgTitle":"Learning classifier system","wgCurRevisionId":951186345,"wgRevisionId":951186345,"wgArticleId":854461,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Evolutionary algorithms"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Learning_classifier_system","wgRelevantArticleId":854461,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],
"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q3509276","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles.legacy":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=[
"ext.cite.ux-enhancements","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.27"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/5/5f/Function_approximation_with_LCS_rules.jpg"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Learning_classifier_system&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Learning_classifier_system&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Learning_classifier_system"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Learning_classifier_system rootpage-Learning_classifier_system skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">Learning classifier system</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"></div>
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Function_approximation_with_LCS_rules.jpg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Function_approximation_with_LCS_rules.jpg/220px-Function_approximation_with_LCS_rules.jpg" decoding="async" width="220" height="311" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Function_approximation_with_LCS_rules.jpg/330px-Function_approximation_with_LCS_rules.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Function_approximation_with_LCS_rules.jpg/440px-Function_approximation_with_LCS_rules.jpg 2x" data-file-width="495" data-file-height="699" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Function_approximation_with_LCS_rules.jpg" class="internal" title="Enlarge"></a></div>2D visualization of LCS rules learning to approximate a 3D function. Each blue ellipse represents an individual rule covering part of the solution space. (Adapted from images taken from XCSF<sup id="cite_ref-:9_1-0" class="reference"><a href="#cite_note-:9-1">&#91;1&#93;</a></sup> with permission from Martin Butz)</div></div></div>
<p><b>Learning classifier systems</b>, or <b>LCS</b>, are a paradigm of <a href="/wiki/Rule-based_machine_learning" title="Rule-based machine learning">rule-based machine learning</a> methods that combine a discovery component (e.g. typically a <a href="/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithm</a>) with a learning component (performing either <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a>, <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>, or <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised learning</a>).<sup id="cite_ref-:1_2-0" class="reference"><a href="#cite_note-:1-2">&#91;2&#93;</a></sup>  Learning classifier systems seek to identify a set of context-dependent rules that collectively store and apply knowledge in a <a href="/wiki/Piecewise" title="Piecewise">piecewise</a> manner in order to make predictions (e.g. <a href="/wiki/Behavior_modeling" class="mw-redirect" title="Behavior modeling">behavior modeling</a>,<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup> <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a>,<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup><sup id="cite_ref-:0_5-0" class="reference"><a href="#cite_note-:0-5">&#91;5&#93;</a></sup> <a href="/wiki/Data_mining" title="Data mining">data mining</a>,<sup id="cite_ref-:0_5-1" class="reference"><a href="#cite_note-:0-5">&#91;5&#93;</a></sup><sup id="cite_ref-6" class="reference"><a href="#cite_note-6">&#91;6&#93;</a></sup><sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup> <a href="/wiki/Regression_analysis" title="Regression analysis">regression</a>,<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup> <a href="/wiki/Function_approximation" title="Function approximation">function approximation</a>,<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup> or <a href="/wiki/Strategy_(game_theory)" title="Strategy (game theory)">game strategy</a>).  This approach allows complex <a href="/wiki/Feasible_region" title="Feasible region">solution spaces</a> to be broken up into smaller, simpler parts.
</p><p>The founding concepts behind learning classifier systems came from attempts to model <a href="/wiki/Complex_adaptive_system" title="Complex adaptive system">complex adaptive systems</a>, using rule-based agents to form an artificial cognitive system (i.e. <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a>).
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Methodology"><span class="tocnumber">1</span> <span class="toctext">Methodology</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Elements_of_a_generic_LCS_algorithm"><span class="tocnumber">1.1</span> <span class="toctext">Elements of a generic LCS algorithm</span></a>
<ul>
<li class="toclevel-3 tocsection-3"><a href="#Environment"><span class="tocnumber">1.1.1</span> <span class="toctext">Environment</span></a></li>
<li class="toclevel-3 tocsection-4"><a href="#Rule/classifier/population"><span class="tocnumber">1.1.2</span> <span class="toctext">Rule/classifier/population</span></a></li>
<li class="toclevel-3 tocsection-5"><a href="#Matching"><span class="tocnumber">1.1.3</span> <span class="toctext">Matching</span></a></li>
<li class="toclevel-3 tocsection-6"><a href="#Covering"><span class="tocnumber">1.1.4</span> <span class="toctext">Covering</span></a></li>
<li class="toclevel-3 tocsection-7"><a href="#Parameter_updates/credit_assignment/learning"><span class="tocnumber">1.1.5</span> <span class="toctext">Parameter updates/credit assignment/learning</span></a></li>
<li class="toclevel-3 tocsection-8"><a href="#Subsumption"><span class="tocnumber">1.1.6</span> <span class="toctext">Subsumption</span></a></li>
<li class="toclevel-3 tocsection-9"><a href="#Rule_discovery/genetic_algorithm"><span class="tocnumber">1.1.7</span> <span class="toctext">Rule discovery/genetic algorithm</span></a></li>
<li class="toclevel-3 tocsection-10"><a href="#Deletion"><span class="tocnumber">1.1.8</span> <span class="toctext">Deletion</span></a></li>
<li class="toclevel-3 tocsection-11"><a href="#Training"><span class="tocnumber">1.1.9</span> <span class="toctext">Training</span></a></li>
<li class="toclevel-3 tocsection-12"><a href="#Rule_compaction"><span class="tocnumber">1.1.10</span> <span class="toctext">Rule compaction</span></a></li>
<li class="toclevel-3 tocsection-13"><a href="#Prediction"><span class="tocnumber">1.1.11</span> <span class="toctext">Prediction</span></a></li>
<li class="toclevel-3 tocsection-14"><a href="#Interpretation"><span class="tocnumber">1.1.12</span> <span class="toctext">Interpretation</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-15"><a href="#History"><span class="tocnumber">2</span> <span class="toctext">History</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Early_years"><span class="tocnumber">2.1</span> <span class="toctext">Early years</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#The_revolution"><span class="tocnumber">2.2</span> <span class="toctext">The revolution</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#In_the_wake_of_XCS"><span class="tocnumber">2.3</span> <span class="toctext">In the wake of XCS</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Variants"><span class="tocnumber">3</span> <span class="toctext">Variants</span></a>
<ul>
<li class="toclevel-2 tocsection-20"><a href="#Michigan-Style_Learning_Classifier_System"><span class="tocnumber">3.1</span> <span class="toctext">Michigan-Style Learning Classifier System</span></a></li>
<li class="toclevel-2 tocsection-21"><a href="#Pittsburgh-Style_Learning_Classifier_System"><span class="tocnumber">3.2</span> <span class="toctext">Pittsburgh-Style Learning Classifier System</span></a></li>
<li class="toclevel-2 tocsection-22"><a href="#Hybrid_systems"><span class="tocnumber">3.3</span> <span class="toctext">Hybrid systems</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-23"><a href="#Advantages"><span class="tocnumber">4</span> <span class="toctext">Advantages</span></a></li>
<li class="toclevel-1 tocsection-24"><a href="#Disadvantages"><span class="tocnumber">5</span> <span class="toctext">Disadvantages</span></a></li>
<li class="toclevel-1 tocsection-25"><a href="#Problem_domains"><span class="tocnumber">6</span> <span class="toctext">Problem domains</span></a></li>
<li class="toclevel-1 tocsection-26"><a href="#Terminology"><span class="tocnumber">7</span> <span class="toctext">Terminology</span></a></li>
<li class="toclevel-1 tocsection-27"><a href="#See_also"><span class="tocnumber">8</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-28"><a href="#References"><span class="tocnumber">9</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-29"><a href="#External_links"><span class="tocnumber">10</span> <span class="toctext">External links</span></a>
<ul>
<li class="toclevel-2 tocsection-30"><a href="#Video_tutorial"><span class="tocnumber">10.1</span> <span class="toctext">Video tutorial</span></a></li>
<li class="toclevel-2 tocsection-31"><a href="#Webpages"><span class="tocnumber">10.2</span> <span class="toctext">Webpages</span></a></li>
</ul>
</li>
</ul>
</div>

<h2><span class="mw-headline" id="Methodology">Methodology</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=1" title="Edit section: Methodology">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The architecture and components of a given learning classifier system can be quite variable.  It is useful to think of an LCS as a machine consisting of several interacting components.  Components may be added or removed, or existing components modified/exchanged to suit the demands of a given problem domain (like algorithmic building blocks) or to make the algorithm flexible enough to function in many different problem domains.  As a result, the LCS paradigm can be flexibly applied to many problem domains that call for <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a>.  The major divisions among LCS implementations are as follows: (1) Michigan-style architecture vs. Pittsburgh-style architecture<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup>, (2) <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> vs. <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a>, (3) incremental learning vs. batch learning, (4) <a href="/wiki/Online_machine_learning" title="Online machine learning">online learning</a> vs. <a href="/wiki/Offline_learning" title="Offline learning">offline learning</a>, (5) strength-based fitness vs. accuracy-based fitness, and (6) complete action mapping vs best action mapping.   These divisions are not necessarily mutually exclusive. For example, XCS,<sup id="cite_ref-:10_11-0" class="reference"><a href="#cite_note-:10-11">&#91;11&#93;</a></sup> the best known and best studied LCS algorithm, is Michigan-style, was designed for reinforcement learning but can also perform supervised learning, applies incremental learning that can be either online or offline, applies accuracy-based fitness, and seeks to generate a complete action mapping.
</p>
<h3><span class="mw-headline" id="Elements_of_a_generic_LCS_algorithm">Elements of a generic LCS algorithm</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=2" title="Edit section: Elements of a generic LCS algorithm">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Generic_Michigan-style_Supervised_LCS_Schematic.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/54/Generic_Michigan-style_Supervised_LCS_Schematic.png/220px-Generic_Michigan-style_Supervised_LCS_Schematic.png" decoding="async" width="220" height="180" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/54/Generic_Michigan-style_Supervised_LCS_Schematic.png/330px-Generic_Michigan-style_Supervised_LCS_Schematic.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/54/Generic_Michigan-style_Supervised_LCS_Schematic.png/440px-Generic_Michigan-style_Supervised_LCS_Schematic.png 2x" data-file-width="3516" data-file-height="2873" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Generic_Michigan-style_Supervised_LCS_Schematic.png" class="internal" title="Enlarge"></a></div>A step-wise schematic illustrating a generic Michigan-style learning classifier system learning cycle performing supervised learning.</div></div></div>
<p>Keeping in mind that LCS is a paradigm for genetic-based machine learning rather than a specific method, the following outlines key elements of a generic, modern (i.e. post-XCS) LCS algorithm.  For simplicity let us focus on Michigan-style architecture with supervised learning.  See the illustrations  on the right laying out the sequential steps involved in this type of generic LCS.
</p>
<h4><span class="mw-headline" id="Environment">Environment</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=3" title="Edit section: Environment">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The environment is the source of data upon which an LCS learns.  It can be an offline, finite <a href="/wiki/Training_data_set" class="mw-redirect" title="Training data set">training dataset</a> (characteristic of a <a href="/wiki/Data_mining" title="Data mining">data mining</a>, <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a>, or regression problem), or an online sequential stream of live training instances.  Each training instance is assumed to include some number of <i>features</i> (also referred to as <i>attributes</i>, or <a href="/wiki/Dependent_and_independent_variables" title="Dependent and independent variables"><i>independent variables</i></a>), and a single <i>endpoint</i> of interest (also referred to as the <a href="/wiki/Class_(set_theory)" title="Class (set theory)">class</a>, <i>action</i>, <i><a href="/wiki/Phenotype" title="Phenotype">phenotype</a></i>, <i>prediction</i>, or <a href="/wiki/Dependent_and_independent_variables" title="Dependent and independent variables"><i>dependent variable</i></a>).  Part of LCS learning can involve <a href="/wiki/Feature_selection" title="Feature selection">feature selection</a>, therefore not all of the features in the training data need be informative.  The set of feature values of an instance is commonly referred to as the <i>state</i>.  For simplicity let's assume an example problem domain with <a href="/wiki/Boolean_data_type" title="Boolean data type">Boolean</a>/<a href="/wiki/Binary_number" title="Binary number">binary</a> features and a <a href="/wiki/Boolean_data_type" title="Boolean data type">Boolean</a>/<a href="/wiki/Binary_number" title="Binary number">binary</a> class.  For Michigan-style systems, one instance from the environment is trained on each learning cycle (i.e. incremental learning).  Pittsburgh-style systems perform batch learning, where rule-sets are evaluated each iteration over much or all of the training data.
</p>
<h4><span id="Rule.2Fclassifier.2Fpopulation"></span><span class="mw-headline" id="Rule/classifier/population">Rule/classifier/population</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=4" title="Edit section: Rule/classifier/population">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>A rule is a context dependent relationship between state values and some prediction.  Rules typically take the form of an {IF:THEN} expression, (e.g.  {<i>IF 'condition' THEN 'action'},</i> or as a more specific example, <i>{IF 'red' AND 'octagon' THEN 'stop-sign'}</i>).   A critical concept in LCS and rule-based machine learning alike, is that an individual rule is not in itself a model, since the rule is only applicable when its condition is satisfied.  Think of a rule as a "local-model" of the solution space.
</p><p>Rules can be represented in many different ways to handle different data types (e.g. binary, discrete-valued, ordinal, continuous-valued).  Given binary data LCS traditionally applies a ternary rule representation (i.e. rules can include either a 0, 1, or '#' for each feature in the data).  The 'don't care' symbol (i.e. '#') serves as a wild card within a rule's condition allowing rules, and the system as a whole to generalize relationships between features and the target endpoint to be predicted. Consider the following rule (#1###0 ~ 1) (i.e. condition ~ action).  This rule can be interpreted as: IF the second feature = 1 AND the sixth feature = 0 THEN the class prediction = 1.  We would say that the second and sixth features were specified in this rule, while the others were generalized. This rule, and the corresponding prediction are only applicable to an instance when the condition of the rule is satisfied by the instance.  This is more commonly referred to as matching.  In Michigan-style LCS, each rule has its own fitness, as well as a number of other rule-parameters associated with it that can describe the number of copies of that rule that exist (i.e. the <i>numerosity</i>), the age of the rule, its accuracy, or the accuracy of its reward predictions, and other descriptive or experiential statistics.  A rule along with its parameters is often referred to as a <i>classifier</i>.  In Michigan-style systems, classifiers are contained within a <i>population</i> [P] that has a user defined maximum number of classifiers.  Unlike most <a href="/wiki/Stochastic" title="Stochastic">stochastic</a> search algorithms (e.g. <a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">evolutionary algorithms</a>), LCS populations start out empty (i.e. there is no need to randomly initialize a rule population).  Classifiers will instead be initially introduced to the population with a covering mechanism.
</p><p>In any LCS, the trained model is a set of rules/classifiers, rather than any single rule/classifier.  In Michigan-style LCS, the entire trained (and optionally, compacted) classifier population forms the prediction model.
</p>
<h4><span class="mw-headline" id="Matching">Matching</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=5" title="Edit section: Matching">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>One of the most critical and often time-consuming elements of an LCS is the matching process.  The first step in an LCS learning cycle takes a single training instance from the environment and passes it to [P] where matching takes place.  In step two, every rule in [P] is now compared to the training instance to see which rules match (i.e. are contextually relevant to the current instance).  In step three, any matching rules are moved to a <i>match set</i> [M].  A rule matches a training instance if all feature values specified in the rule condition are equivalent to the corresponding feature value in the training instance.  For example, assuming the training instance is (001001 ~ 0), these rules would match: (###0## ~ 0), (00###1 ~ 0), (#01001 ~ 1), but these rules would not (1##### ~ 0), (000##1 ~ 0), (#0#1#0 ~ 1).  Notice that in matching, the endpoint/action specified by the rule is not taken into consideration.  As a result, the match set may contain classifiers that propose conflicting actions.  In the fourth step, since we are performing supervised learning, [M] is divided into a correct set [C] and an incorrect set [I].  A matching rule goes into the correct set if it proposes the correct action (based on the known action of the training instance), otherwise it goes into [I].  In reinforcement learning LCS, an action set [A] would be formed here instead, since the correct action is not known.
</p>
<h4><span class="mw-headline" id="Covering">Covering</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=6" title="Edit section: Covering">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>At this point in the learning cycle, if no classifiers made it into either [M] or [C] (as would be the case when the population starts off empty), the covering mechanism is applied (fifth step).  Covering is a form of <i>online smart population initialization</i>. Covering randomly generates a rule that matches the current training instance (and in the case of supervised learning, that rule is also generated with the correct action.  Assuming the training instance is (001001 ~ 0), covering might generate any of the following rules:  (#0#0## ~ 0), (001001 ~ 0), (#010## ~ 0).  Covering not only ensures that each learning cycle there is at least one correct, matching rule in [C], but that any rule initialized into the population will match at least one training instance.  This prevents LCS from exploring the search space of rules that do not match any training instances.
</p>
<h4><span id="Parameter_updates.2Fcredit_assignment.2Flearning"></span><span class="mw-headline" id="Parameter_updates/credit_assignment/learning">Parameter updates/credit assignment/learning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=7" title="Edit section: Parameter updates/credit assignment/learning">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In the sixth step, the rule parameters of any rule in [M] are updated to reflect the new experience gained from the current training instance.  Depending on the LCS algorithm, a number of updates can take place at this step.  For supervised learning, we can simply update the accuracy/error of a rule.  Rule accuracy/error is different than model accuracy/error, since it is not calculated over the entire training data, but only over all instances that it matched.  Rule accuracy is calculated by dividing the number of times the rule was in a correct set [C] by the number of times it was in a match set [M].  Rule accuracy can be thought of as a 'local accuracy'.  Rule fitness is also updated here, and is commonly calculated as a function of rule accuracy.  The concept of fitness is taken directly from classic <a href="/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithms</a>.  Be aware that there are many variations on how LCS updates parameters in order to perform credit assignment and learning.
</p>
<h4><span class="mw-headline" id="Subsumption">Subsumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=8" title="Edit section: Subsumption">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In the seventh step, a <i>subsumption</i> mechanism is typically applied.  Subsumption is an explicit generalization mechanism that merges classifiers that cover redundant parts of the problem space.  The subsuming classifier effectively absorbs the subsumed classifier (and has its numerosity increased).  This can only happen when the subsuming classifier is more general, just as accurate, and covers all of the problem space of the classifier it subsumes.
</p>
<h4><span id="Rule_discovery.2Fgenetic_algorithm"></span><span class="mw-headline" id="Rule_discovery/genetic_algorithm">Rule discovery/genetic algorithm</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=9" title="Edit section: Rule discovery/genetic algorithm">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In the eighth step, LCS adopts a highly elitist <a href="/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithm</a> (GA) which will select two parent classifiers based on fitness (survival of the fittest).  Parents are selected from [C] typically using <a href="/wiki/Tournament_selection" title="Tournament selection">tournament selection</a>.  Some systems have applied <a href="/wiki/Roulette_wheel_selection" class="mw-redirect" title="Roulette wheel selection">roulette wheel selection</a> or deterministic selection, and have differently selected parent rules from either [P] - panmictic selection, or from [M]).  <a href="/wiki/Crossover_(genetic_algorithm)" title="Crossover (genetic algorithm)">Crossover</a> and <a href="/wiki/Mutation_(genetic_algorithm)" title="Mutation (genetic algorithm)">mutation</a> operators are now applied to generate two new offspring rules.  At this point, both the parent and offspring rules are returned to [P].  The LCS <a href="/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithm</a> is highly elitist since each learning iteration, the vast majority of the population is preserved.  Rule discovery may alternatively be performed by some other method, such as an <a href="/wiki/Estimation_of_distribution_algorithm" title="Estimation of distribution algorithm">estimation of distribution algorithm</a>, but a GA is by far the most common approach.  Evolutionary algorithms like the GA employ a stochastic search, which makes LCS a stochastic algorithm.  LCS seeks to cleverly explore the search space, but does not perform an exhaustive search of rule combinations, and is not guaranteed to converge on an optimal solution.
</p>
<h4><span class="mw-headline" id="Deletion">Deletion</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=10" title="Edit section: Deletion">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The last step in a generic LCS learning cycle is to maintain the maximum population size. The deletion mechanism will select classifiers for deletion (commonly using roulette wheel selection).  The probability of a classifier being selected for deletion is inversely proportional to its fitness.  When a classifier is selected for deletion, its numerosity parameter is reduced by one.  When the numerosity of a classifier is reduced to zero, it is removed entirely from the population.
</p>
<h4><span class="mw-headline" id="Training">Training</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=11" title="Edit section: Training">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>LCS will cycle through these steps repeatedly for some user defined number of training iterations, or until some user defined termination criteria have been met.  For online learning, LCS will obtain a completely new training instance each iteration from the environment.  For offline learning, LCS will iterate through a finite training dataset.  Once it reaches the last instance in the dataset, it will go back to the first instance and cycle through the dataset again.
</p>
<h4><span class="mw-headline" id="Rule_compaction">Rule compaction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=12" title="Edit section: Rule compaction">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Once training is complete, the rule population will inevitably contain some poor, redundant and inexperienced rules.  It is common to apply a <i>rule compaction</i>, or <i>condensation</i> heuristic as a post-processing step.  This resulting compacted rule population is ready to be applied as a prediction model (e.g. make predictions on testing instances), and/or to be interpreted for <a href="/wiki/Knowledge_discovery" class="mw-redirect" title="Knowledge discovery">knowledge discovery</a>.
</p>
<h4><span class="mw-headline" id="Prediction">Prediction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=13" title="Edit section: Prediction">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Whether or not rule compaction has been applied, the output of an LCS algorithm is a population of classifiers which can be applied to making predictions on previously unseen instances.  The prediction mechanism is not part of the supervised LCS learning cycle itself, however it would play an important role in a reinforcement learning LCS learning cycle.  For now we consider how the prediction mechanism can be applied for making predictions to test data.  When making predictions, the LCS learning components are deactivated so that the population does not continue to learn from incoming testing data.  A test instance is passed to [P] where a match set [M] is formed as usual.  At this point the match set is differently passed to a prediction array.  Rules in the match set can predict different actions, therefore a voting scheme is applied.  In a simple voting scheme, the action with the strongest supporting 'votes' from matching rules wins, and becomes the selected prediction.  All rules do not get an equal vote.  Rather the strength of the vote for a single rule is commonly proportional to its numerosity and fitness.  This voting scheme and the nature of how LCS's store knowledge, suggests that LCS algorithms are implicitly <i>ensemble learners</i>.
</p>
<h4><span class="mw-headline" id="Interpretation">Interpretation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=14" title="Edit section: Interpretation">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Individual LCS rules are typically human readable IF:THEN expression.  Rules that constitute the LCS prediction model can be ranked by different rule parameters and manually inspected.  Global strategies to guide knowledge discovery using statistical and graphical have also been proposed.<sup id="cite_ref-:11_12-0" class="reference"><a href="#cite_note-:11-12">&#91;12&#93;</a></sup><sup id="cite_ref-:12_13-0" class="reference"><a href="#cite_note-:12-13">&#91;13&#93;</a></sup>  With respect to other advanced machine learning approaches, such as <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a>, <a href="/wiki/Random_forest" title="Random forest">random forests</a>, or <a href="/wiki/Genetic_programming" title="Genetic programming">genetic programming</a>, learning classifier systems are particularly well suited to problems that require interpretable solutions.
</p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=15" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Early_years">Early years</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=16" title="Edit section: Early years">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/John_Henry_Holland" title="John Henry Holland">John Henry Holland</a> was best known for his work popularizing <a href="/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithms</a> (GA), through his ground-breaking book "Adaptation in Natural and Artificial Systems"<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup> in 1975 and his formalization of <a href="/wiki/Holland%27s_schema_theorem" title="Holland&#39;s schema theorem">Holland's schema theorem</a>.  In 1976, Holland conceptualized an extension of the GA concept to what he called a "cognitive system",<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup> and provided the first detailed description of what would become known as the first learning classifier system in the paper "Cognitive Systems based on Adaptive Algorithms".<sup id="cite_ref-:2_16-0" class="reference"><a href="#cite_note-:2-16">&#91;16&#93;</a></sup>  This first system, named <b>Cognitive System One (CS-1)</b> was conceived as a modeling tool, designed to model a real system (i.e. <i>environment</i>) with unknown underlying dynamics using a population of human readable rules.  The goal was for a set of rules to perform <a href="/wiki/Online_machine_learning" title="Online machine learning">online machine learning</a> to adapt to the environment based on infrequent payoff/reward (i.e. reinforcement learning) and apply these rules to generate a behavior that matched the real system. This early, ambitious implementation was later regarded as overly complex, yielding inconsistent results.<sup id="cite_ref-:1_2-1" class="reference"><a href="#cite_note-:1-2">&#91;2&#93;</a></sup><sup id="cite_ref-:3_17-0" class="reference"><a href="#cite_note-:3-17">&#91;17&#93;</a></sup>
</p><p>Beginning in 1980, <a href="/wiki/Kenneth_A_De_Jong" title="Kenneth A De Jong">Kenneth de Jong</a> and his student Stephen Smith took a different approach to rule-based machine learning with <b>(LS-1)</b>, where learning was viewed as an offline optimization process rather than an online adaptation process.<sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup><sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;19&#93;</a></sup><sup id="cite_ref-20" class="reference"><a href="#cite_note-20">&#91;20&#93;</a></sup>  This new approach was more similar to a standard genetic algorithm but evolved independent sets of rules.  Since that time LCS methods inspired by the online learning framework introduced by Holland at the University of Michigan have been referred to as <b>Michigan-style LCS</b>, and those inspired by Smith and De Jong at the University of Pittsburgh have been referred to as <b>Pittsburgh-style LCS</b>.<sup id="cite_ref-:1_2-2" class="reference"><a href="#cite_note-:1-2">&#91;2&#93;</a></sup><sup id="cite_ref-:3_17-1" class="reference"><a href="#cite_note-:3-17">&#91;17&#93;</a></sup>  In 1986, Holland developed what would be considered the standard Michigan-style LCS for the next decade.<sup id="cite_ref-:4_21-0" class="reference"><a href="#cite_note-:4-21">&#91;21&#93;</a></sup>
</p><p>Other important concepts that emerged in the early days of LCS research included (1) the formalization of a <i>bucket brigade algorithm</i> (BBA) for credit assignment/learning,<sup id="cite_ref-22" class="reference"><a href="#cite_note-22">&#91;22&#93;</a></sup> (2) selection of parent rules from a common 'environmental niche' (i.e. the <i>match set</i> [M]) rather than from the whole <i>population</i> [P],<sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;23&#93;</a></sup> (3) <i>covering</i>, first introduced as a <i>create</i> operator,<sup id="cite_ref-:5_24-0" class="reference"><a href="#cite_note-:5-24">&#91;24&#93;</a></sup> (4) the formalization of an <i>action set</i> [A],<sup id="cite_ref-:5_24-1" class="reference"><a href="#cite_note-:5-24">&#91;24&#93;</a></sup> (5) a simplified algorithm architecture,<sup id="cite_ref-:5_24-2" class="reference"><a href="#cite_note-:5-24">&#91;24&#93;</a></sup> (6) <i>strength-based fitness</i>,<sup id="cite_ref-:4_21-1" class="reference"><a href="#cite_note-:4-21">&#91;21&#93;</a></sup> (7) consideration of single-step, or supervised learning problems<sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> and the introduction of the <i>correct set</i> [C],<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup> (8) <i>accuracy-based fitness</i><sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup> (9) the combination of fuzzy logic with LCS<sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup> (which later spawned a lineage of <i>fuzzy LCS algorithms</i>), (10) encouraging <i>long action chains</i> and <i>default hierarchies</i> for improving performance on multi-step problems,<sup id="cite_ref-29" class="reference"><a href="#cite_note-29">&#91;29&#93;</a></sup><sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;30&#93;</a></sup><sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></sup> (11) examining <a href="/wiki/Latent_learning" title="Latent learning">latent learning</a> (which later inspired a new branch of <i>anticipatory classifier systems</i> (ACS)<sup id="cite_ref-:7_32-0" class="reference"><a href="#cite_note-:7-32">&#91;32&#93;</a></sup>), and (12) the introduction of the first <a href="/wiki/Q-learning" title="Q-learning">Q-learning</a>-like credit assignment technique.<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup>  While not all of these concepts are applied in modern LCS algorithms, each were landmarks in the development of the LCS paradigm.
</p>
<h3><span class="mw-headline" id="The_revolution">The revolution</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=17" title="Edit section: The revolution">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Interest in learning classifier systems was reinvigorated in the mid 1990s largely due to two events; the development of the <a href="/wiki/Q-learning" title="Q-learning">Q-Learning</a> algorithm<sup id="cite_ref-34" class="reference"><a href="#cite_note-34">&#91;34&#93;</a></sup> for <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>, and the introduction of significantly simplified Michigan-style LCS architectures by Stewart Wilson.<sup id="cite_ref-:10_11-1" class="reference"><a href="#cite_note-:10-11">&#91;11&#93;</a></sup><sup id="cite_ref-:6_35-0" class="reference"><a href="#cite_note-:6-35">&#91;35&#93;</a></sup>  Wilson's <b>Zeroth-level Classifier System (ZCS)</b><sup id="cite_ref-:6_35-1" class="reference"><a href="#cite_note-:6-35">&#91;35&#93;</a></sup> focused on increasing algorithmic understandability based on Hollands standard LCS implementation.<sup id="cite_ref-:4_21-2" class="reference"><a href="#cite_note-:4-21">&#91;21&#93;</a></sup>  This was done, in part, by removing rule-bidding and the internal message list, essential to the original BBA credit assignment, and replacing it with a hybrid BBA/<a href="/wiki/Q-learning" title="Q-learning">Q-Learning</a> strategy.  ZCS demonstrated that a much simpler LCS architecture could perform as well as the original, more complex implementations.  However, ZCS still suffered from performance drawbacks including the proliferation of over-general classifiers.
</p><p>In 1995, Wilson published his landmark paper, "Classifier fitness based on accuracy" in which he introduced the classifier system <b>XCS</b>.<sup id="cite_ref-:10_11-2" class="reference"><a href="#cite_note-:10-11">&#91;11&#93;</a></sup>  XCS took the simplified architecture of ZCS and added an accuracy-based fitness, a niche GA (acting in the action set [A]), an explicit generalization mechanism called <i>subsumption</i>, and an adaptation of the <a href="/wiki/Q-learning" title="Q-learning">Q-Learning</a> credit assignment.  XCS was popularized by its ability to reach optimal performance while evolving accurate and maximally general classifiers as well as its impressive problem flexibility (able to perform both <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> and <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a>). XCS later became the best known and most studied LCS algorithm and defined a new family of <i>accuracy-based LCS</i>.  ZCS alternatively became synonymous with <i>strength-based LCS</i>.  XCS is also important, because it successfully bridged the gap between LCS and the field of <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>.  Following the success of XCS, LCS were later described as reinforcement learning systems endowed with a generalization capability.<sup id="cite_ref-36" class="reference"><a href="#cite_note-36">&#91;36&#93;</a></sup>  <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a> typically seeks to learn a value function that maps out a complete representation of the state/action space.  Similarly, the design of XCS drives it to form an all-inclusive and accurate representation of the problem space (i.e. a <i>complete map</i>) rather than focusing on high payoff niches in the environment (as was the case with strength-based LCS).  Conceptually, complete maps don't only capture what you should do, or what is correct, but also what you shouldn't do, or what's incorrect.  Differently, most strength-based LCSs, or exclusively supervised learning LCSs seek a rule set of efficient generalizations in the form of a <i>best action map</i> (or a <i>partial map</i>).   Comparisons between strength vs. accuracy-based fitness and complete vs. best action maps have since been examined in greater detail.<sup id="cite_ref-37" class="reference"><a href="#cite_note-37">&#91;37&#93;</a></sup><sup id="cite_ref-38" class="reference"><a href="#cite_note-38">&#91;38&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="In_the_wake_of_XCS">In the wake of XCS</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=18" title="Edit section: In the wake of XCS">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>XCS inspired the development of a whole new generation of LCS algorithms and applications.  In 1995, Congdon was the first to apply LCS to real-world <a href="/wiki/Epidemiology" title="Epidemiology">epidemiological</a> investigations of disease <sup id="cite_ref-:8_39-0" class="reference"><a href="#cite_note-:8-39">&#91;39&#93;</a></sup> followed closely by Holmes who developed the <b>BOOLE++</b>,<sup id="cite_ref-40" class="reference"><a href="#cite_note-40">&#91;40&#93;</a></sup> <b>EpiCS</b>,<sup id="cite_ref-41" class="reference"><a href="#cite_note-41">&#91;41&#93;</a></sup> and later <b>EpiXCS</b><sup id="cite_ref-42" class="reference"><a href="#cite_note-42">&#91;42&#93;</a></sup> for <a href="/wiki/Epidemiology" title="Epidemiology">epidemiological</a> classification.  These early works inspired later interest in applying LCS algorithms to complex and large-scale <a href="/wiki/Data_mining" title="Data mining">data mining</a> tasks epitomized by <a href="/wiki/Bioinformatics" title="Bioinformatics">bioinformatics</a> applications.  In 1998, Stolzmann introduced <b>anticipatory classifier systems (ACS)</b> which included rules in the form of 'condition-action-effect, rather than the classic 'condition-action' representation.<sup id="cite_ref-:7_32-1" class="reference"><a href="#cite_note-:7-32">&#91;32&#93;</a></sup>  ACS was designed to predict the perceptual consequences of an action in all possible situations in an environment.  In other words, the system evolves a model that specifies not only what to do in a given situation, but also provides information of what will happen after a specific action will be executed. This family of LCS algorithms is best suited to multi-step problems, planning, speeding up learning, or disambiguating perceptual aliasing (i.e. where the same observation is obtained in distinct states but requires different actions).  Butz later pursued this anticipatory family of LCS developing a number of improvements to the original method.<sup id="cite_ref-43" class="reference"><a href="#cite_note-43">&#91;43&#93;</a></sup>  In 2002, Wilson introduced <b>XCSF</b>, adding a computed action in order to perform function approximation.<sup id="cite_ref-44" class="reference"><a href="#cite_note-44">&#91;44&#93;</a></sup>  In 2003, Bernado-Mansilla introduced a <b>sUpervised Classifier System (UCS)</b>, which specialized the XCS algorithm to the task of <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a>, single-step problems, and forming a best action set.  UCS removed the <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> strategy in favor of a simple, accuracy-based rule fitness as well as the explore/exploit learning phases, characteristic of many reinforcement learners.  Bull introduced a simple accuracy-based LCS <b>(YCS)</b><sup id="cite_ref-45" class="reference"><a href="#cite_note-45">&#91;45&#93;</a></sup> and a simple strength-based LCS <b>Minimal Classifier System (MCS)</b><sup id="cite_ref-46" class="reference"><a href="#cite_note-46">&#91;46&#93;</a></sup> in order to develop a better theoretical understanding of the LCS framework.  Bacardit introduced <b>GAssist</b><sup id="cite_ref-47" class="reference"><a href="#cite_note-47">&#91;47&#93;</a></sup> and <b>BioHEL</b>,<sup id="cite_ref-48" class="reference"><a href="#cite_note-48">&#91;48&#93;</a></sup> Pittsburgh-style LCSs designed for <a href="/wiki/Data_mining" title="Data mining">data mining</a> and <a href="/wiki/Scalability" title="Scalability">scalability</a> to large datasets in <a href="/wiki/Bioinformatics" title="Bioinformatics">bioinformatics</a> applications.  In 2008, Drugowitsch published the book titled "Design and Analysis of Learning Classifier Systems" including some theoretical examination of LCS algorithms.<sup id="cite_ref-49" class="reference"><a href="#cite_note-49">&#91;49&#93;</a></sup>  Butz introduced the first rule online learning visualization within a <a href="/wiki/Graphical_user_interface" title="Graphical user interface">GUI</a> for XCSF<sup id="cite_ref-:9_1-1" class="reference"><a href="#cite_note-:9-1">&#91;1&#93;</a></sup> (see the image at the top of this page).  Urbanowicz extended the UCS framework and introduced <b>ExSTraCS,</b> explicitly designed for <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a> in noisy problem domains (e.g. epidemiology and bioinformatics).<sup id="cite_ref-50" class="reference"><a href="#cite_note-50">&#91;50&#93;</a></sup>  ExSTraCS integrated (1) expert knowledge to drive covering and genetic algorithm towards important features in the data,<sup id="cite_ref-51" class="reference"><a href="#cite_note-51">&#91;51&#93;</a></sup> (2) a form of long-term memory referred to as attribute tracking,<sup id="cite_ref-52" class="reference"><a href="#cite_note-52">&#91;52&#93;</a></sup> allowing for more efficient learning and the characterization of heterogeneous data patterns, and (3) a flexible rule representation similar to Bacardit's mixed discrete-continuous attribute list representation.<sup id="cite_ref-53" class="reference"><a href="#cite_note-53">&#91;53&#93;</a></sup>  Both Bacardit and Urbanowicz explored statistical and visualization strategies to interpret LCS rules and perform knowledge discovery for data mining.<sup id="cite_ref-:11_12-1" class="reference"><a href="#cite_note-:11-12">&#91;12&#93;</a></sup><sup id="cite_ref-:12_13-1" class="reference"><a href="#cite_note-:12-13">&#91;13&#93;</a></sup>  Browne and Iqbal explored the concept of reusing building blocks in the form of code fragments and were the first to solve the 135-bit multiplexer benchmark problem by first learning useful building blocks from simpler multiplexer problems.<sup id="cite_ref-54" class="reference"><a href="#cite_note-54">&#91;54&#93;</a></sup> <b>ExSTraCS 2.0</b> was later introduced to improve Michigan-style LCS scalability, successfully solving the 135-bit multiplexer benchmark problem for the first time directly.<sup id="cite_ref-:0_5-2" class="reference"><a href="#cite_note-:0-5">&#91;5&#93;</a></sup>  The n-bit <a href="/wiki/Multiplexer" title="Multiplexer">multiplexer</a> problem is highly <a href="/wiki/Epistasis" title="Epistasis">epistatic</a> and <a href="/wiki/Homogeneity_and_heterogeneity" title="Homogeneity and heterogeneity">heterogeneous</a>, making it a very challenging <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> task.
</p>
<h2><span class="mw-headline" id="Variants">Variants</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=19" title="Edit section: Variants">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Michigan-Style_Learning_Classifier_System">Michigan-Style Learning Classifier System</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=20" title="Edit section: Michigan-Style Learning Classifier System">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Michigan-Style LCSs are characterized by a population of rules where the genetic algorithm operates at the level of individual rules and the solution is represented by the entire rule population.  Michigan style systems also learn incrementally which allows them to perform both reinforcement learning and supervised learning, as well as both online and offline learning.  Michigan-style systems have the advantage of being applicable to a greater number of problem domains, and the unique benefits of incremental learning.
</p>
<h3><span class="mw-headline" id="Pittsburgh-Style_Learning_Classifier_System">Pittsburgh-Style Learning Classifier System</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=21" title="Edit section: Pittsburgh-Style Learning Classifier System">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Pittsburgh-Style LCSs are characterized by a population of variable length rule-sets where each rule-set is a potential solution.  The genetic algorithm typically operates at the level of an entire rule-set.  Pittsburgh-style systems can also uniquely evolve ordered rule lists, as well as employ a default rule.  These systems have the natural advantage of identifying smaller rule sets, making these systems more interpretable with regards to manual rule inspection.
</p>
<h3><span class="mw-headline" id="Hybrid_systems">Hybrid systems</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=22" title="Edit section: Hybrid systems">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Systems that seek to combine key strengths of both systems have also been proposed.
</p>
<h2><span class="mw-headline" id="Advantages">Advantages</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=23" title="Edit section: Advantages">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li>Adaptive: They can acclimate to a changing environment in the case of online learning.</li>
<li>Model free: They make limited assumptions about the environment, or the patterns of association within the data.
<ul><li>The can model complex, epistatic, heterogeneous, or distributed underlying patterns without relying on prior knowledge.</li>
<li>They make no assumptions about the number of predictive vs. non-predictive features in the data.</li></ul></li>
<li>Ensemble Learner: No single model is applied to a given instance that universally provides a prediction.  Instead a relevant and often conflicting set of rules contribute a 'vote' which can be interpreted as a fuzzy prediction.</li>
<li>Stochastic Learner: Non-deterministic learning is advantageous in large-scale or high complexity problems where deterministic or exhaustive learning becomes intractable.</li>
<li>Implicitly Multi-objective: Rules evolve towards accuracy with implicit and explicit pressures encouraging maximal generality/simplicity. This implicit generalization pressure is unique to LCS.  Effectively, more general rules, will appear more often in match sets.  In turn, they have a more frequent opportunity to be selected as parents, and pass on their more general (genomes) to offspring rules.</li>
<li>Interpretable:In the interest of data mining and knowledge discovery individual LCS rules are logical, and can be made to be human interpretable IF:THEN statements.  Effective strategies have also been introduced to allow for global knowledge discovery identifying significant features, and patterns of association from the rule population as a whole.<sup id="cite_ref-:11_12-2" class="reference"><a href="#cite_note-:11-12">&#91;12&#93;</a></sup></li>
<li>Flexible application
<ul><li>Single or multi-step problems</li>
<li>Supervised, Reinforcement or Unsupervised Learning</li>
<li>Binary Class and Multi-Class Classification</li>
<li>Regression</li>
<li>Discrete or continuous features (or some mix of both types)</li>
<li>Clean or noisy problem domains</li>
<li>Balanced or imbalanced datasets.</li>
<li>Accommodates missing data (i.e. missing feature values in training instances)</li></ul></li></ul>
<h2><span class="mw-headline" id="Disadvantages">Disadvantages</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=24" title="Edit section: Disadvantages">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li>Limited Software Availability: There are a limited number of open source, accessible LCS implementations, and even fewer that are designed to be user friendly or accessible to machine learning practitioners.</li>
<li>Interpretation:  While LCS algorithms are certainly more interpretable than some advanced machine learners, users must interpret a set of rules (sometimes large sets of rules to comprehend the LCS model.). Methods for rule compaction, and interpretation strategies remains an area of active research.</li>
<li>Theory/Convergence Proofs:  There is a relatively small body of theoretical work behind LCS algorithms.  This is likely due to their relative algorithmic complexity (applying a number of interacting components) as well as their stochastic nature.</li>
<li>Overfitting:  Like any machine learner, LCS can suffer from <a href="/wiki/Overfitting" title="Overfitting">overfitting</a> despite implicit and explicit generalization pressures.</li>
<li>Run Parameters: LCSs often have many run parameters to consider/optimize. Typically, most parameters can be left to the community determined defaults with the exception of two critical parameters: Maximum rule population size, and the maximum number of learning iterations.   Optimizing these parameters are likely to be very problem dependent.</li>
<li>Notoriety:  Despite their age, LCS algorithms are still not widely known even in machine learning communities.  As a result, LCS algorithms are rarely considered in comparison to other established machine learning approaches.  This is likely due to the following factors:  (1) LCS is a relatively complicated algorithmic approach, (2) LCS, rule-based modeling is a different paradigm of modeling than almost all other machine learning approaches. (3) LCS software implementations are not as common.</li>
<li>Computationally Expensive:  While certainly more feasible than some exhaustive approaches, LCS algorithms can be computationally expensive.  For simple, linear learning problems there is no need to apply an LCS.  LCS algorithms are best suited to complex problem spaces, or problem spaces in which little prior knowledge exists.</li></ul>
<h2><span class="mw-headline" id="Problem_domains">Problem domains</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=25" title="Edit section: Problem domains">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li>Adaptive-control</li>
<li>Data Mining</li>
<li>Engineering Design</li>
<li>Feature Selection</li>
<li>Function Approximation</li>
<li>Game-Play</li>
<li>Image Classification</li>
<li>Knowledge Handeling</li>
<li>Medical Diagnosis</li>
<li>Modeling</li>
<li>Navigation</li>
<li>Optimization</li>
<li>Prediction</li>
<li>Querying</li>
<li>Robotics</li>
<li>Routing</li>
<li>Rule-Induction</li>
<li>Scheduling</li>
<li>Strategy</li></ul>
<h2><span class="mw-headline" id="Terminology">Terminology</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=26" title="Edit section: Terminology">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The name, "Learning Classifier System (LCS)", is a bit misleading since there are many <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> algorithms that 'learn to classify' (e.g. <a href="/wiki/Decision_tree" title="Decision tree">decision trees</a>, <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a>), but are not LCSs.  The term 'rule-based machine learning (<a href="/wiki/Rule-based_machine_learning" title="Rule-based machine learning">RBML</a>)' is useful, as it more clearly captures the essential 'rule-based' component of these systems, but it also generalizes to methods that are not considered to be LCSs (e.g. <a href="/wiki/Association_rule_learning" title="Association rule learning">association rule learning</a>, or <a href="/wiki/Artificial_immune_system" title="Artificial immune system">artificial immune systems</a>). More general terms such as, 'genetics-based machine learning', and even 'genetic algorithm'<sup id="cite_ref-:8_39-1" class="reference"><a href="#cite_note-:8-39">&#91;39&#93;</a></sup> have also been applied to refer to what would be more characteristically defined as a learning classifier system.  Due to their similarity to <a href="/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithms</a>, Pittsburgh-style learning classifier systems are sometimes generically referred to as 'genetic algorithms'.  Beyond this, some LCS algorithms, or closely related methods, have been referred to as 'cognitive systems',<sup id="cite_ref-:2_16-1" class="reference"><a href="#cite_note-:2-16">&#91;16&#93;</a></sup> 'adaptive agents', '<a href="/wiki/Production_system_(computer_science)" title="Production system (computer science)">production systems</a>', or generically as a 'classifier system'.<sup id="cite_ref-55" class="reference"><a href="#cite_note-55">&#91;55&#93;</a></sup><sup id="cite_ref-56" class="reference"><a href="#cite_note-56">&#91;56&#93;</a></sup>   This variation in terminology contributes to some confusion in the field.
</p><p>Up until the 2000s nearly all learning classifier system methods were developed with reinforcement learning problems in mind. As a result, the term ‘learning classifier system’ was commonly defined as the combination of ‘trial-and-error’ reinforcement learning with the global search of a genetic algorithm. Interest in supervised learning applications, and even unsupervised learning have since broadened the use and definition of this term.
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=27" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li>Rule-based machine learning</li>
<li><a href="/wiki/Production_system_(computer_science)" title="Production system (computer science)">Production system</a></li>
<li><a href="/wiki/Expert_system" title="Expert system">Expert system</a></li>
<li><a href="/wiki/Genetic_algorithm" title="Genetic algorithm">Genetic algorithm</a></li>
<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rule learning</a></li>
<li><a href="/wiki/Artificial_immune_system" title="Artificial immune system">Artificial immune system</a></li>
<li><a href="/wiki/Population-based_incremental_learning" title="Population-based incremental learning">Population-based Incremental Learning</a></li>
<li><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=28" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-:9-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-:9_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:9_1-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Stalph, Patrick O.; Butz, Martin V. (2010-02-01). "JavaXCSF: The XCSF Learning Classifier System in Java". <i>SIGEVOlution</i>. <b>4</b> (3): 16–19. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F1731888.1731890">10.1145/1731888.1731890</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1931-8499">1931-8499</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=SIGEVOlution&amp;rft.atitle=JavaXCSF%3A+The+XCSF+Learning+Classifier+System+in+Java&amp;rft.volume=4&amp;rft.issue=3&amp;rft.pages=16-19&amp;rft.date=2010-02-01&amp;rft_id=info%3Adoi%2F10.1145%2F1731888.1731890&amp;rft.issn=1931-8499&amp;rft.aulast=Stalph&amp;rft.aufirst=Patrick+O.&amp;rft.au=Butz%2C+Martin+V.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-:1-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-:1_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:1_2-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:1_2-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Urbanowicz, Ryan J.; Moore, Jason H. (2009-09-22). "Learning Classifier Systems: A Complete Introduction, Review, and Roadmap". <i>Journal of Artificial Evolution and Applications</i>. <b>2009</b>: 1–25. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1155%2F2009%2F736398">10.1155/2009/736398</a></span>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1687-6229">1687-6229</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Artificial+Evolution+and+Applications&amp;rft.atitle=Learning+Classifier+Systems%3A+A+Complete+Introduction%2C+Review%2C+and+Roadmap&amp;rft.volume=2009&amp;rft.pages=1-25&amp;rft.date=2009-09-22&amp;rft_id=info%3Adoi%2F10.1155%2F2009%2F736398&amp;rft.issn=1687-6229&amp;rft.aulast=Urbanowicz&amp;rft.aufirst=Ryan+J.&amp;rft.au=Moore%2C+Jason+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite class="citation journal">Dorigo, Marco (1995). "Alecsys and the AutonoMouse: Learning to control a real robot by distributed classifier systems". <i>Machine Learning</i>. <b>19</b> (3): 209–240. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1007%2FBF00996270">10.1007/BF00996270</a></span>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0885-6125">0885-6125</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Alecsys+and+the+AutonoMouse%3A+Learning+to+control+a+real+robot+by+distributed+classifier+systems&amp;rft.volume=19&amp;rft.issue=3&amp;rft.pages=209-240&amp;rft.date=1995&amp;rft_id=info%3Adoi%2F10.1007%2FBF00996270&amp;rft.issn=0885-6125&amp;rft.aulast=Dorigo&amp;rft.aufirst=Marco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bernadó-Mansilla, Ester; Garrell-Guiu, Josep M. (2003-09-01). "Accuracy-Based Learning Classifier Systems: Models, Analysis and Applications to Classification Tasks". <i>Evolutionary Computation</i>. <b>11</b> (3): 209–238. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2F106365603322365289">10.1162/106365603322365289</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1063-6560">1063-6560</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/14558911">14558911</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Evolutionary+Computation&amp;rft.atitle=Accuracy-Based+Learning+Classifier+Systems%3A+Models%2C+Analysis+and+Applications+to+Classification+Tasks&amp;rft.volume=11&amp;rft.issue=3&amp;rft.pages=209-238&amp;rft.date=2003-09-01&amp;rft.issn=1063-6560&amp;rft_id=info%3Apmid%2F14558911&amp;rft_id=info%3Adoi%2F10.1162%2F106365603322365289&amp;rft.aulast=Bernad%C3%B3-Mansilla&amp;rft.aufirst=Ester&amp;rft.au=Garrell-Guiu%2C+Josep+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-:0-5"><span class="mw-cite-backlink">^ <a href="#cite_ref-:0_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_5-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:0_5-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Urbanowicz, Ryan J.; Moore, Jason H. (2015-04-03). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4583133">"ExSTraCS 2.0: description and evaluation of a scalable learning classifier system"</a>. <i>Evolutionary Intelligence</i>. <b>8</b> (2–3): 89–116. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs12065-015-0128-8">10.1007/s12065-015-0128-8</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1864-5909">1864-5909</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4583133">4583133</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/26417393">26417393</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Evolutionary+Intelligence&amp;rft.atitle=ExSTraCS+2.0%3A+description+and+evaluation+of+a+scalable+learning+classifier+system&amp;rft.volume=8&amp;rft.issue=2%E2%80%933&amp;rft.pages=89-116&amp;rft.date=2015-04-03&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4583133&amp;rft.issn=1864-5909&amp;rft_id=info%3Apmid%2F26417393&amp;rft_id=info%3Adoi%2F10.1007%2Fs12065-015-0128-8&amp;rft.aulast=Urbanowicz&amp;rft.aufirst=Ryan+J.&amp;rft.au=Moore%2C+Jason+H.&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4583133&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite class="citation book">Bernadó, Ester; Llorà, Xavier; Garrell, Josep M. (2001-07-07).  Lanzi, Pier Luca; Stolzmann, Wolfgang; Wilson, Stewart W. (eds.). <i>Advances in Learning Classifier Systems</i>. Lecture Notes in Computer Science. Springer Berlin Heidelberg. pp.&#160;115–132. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F3-540-48104-4_8">10.1007/3-540-48104-4_8</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9783540437932" title="Special:BookSources/9783540437932"><bdi>9783540437932</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Advances+in+Learning+Classifier+Systems&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=115-132&amp;rft.pub=Springer+Berlin+Heidelberg&amp;rft.date=2001-07-07&amp;rft_id=info%3Adoi%2F10.1007%2F3-540-48104-4_8&amp;rft.isbn=9783540437932&amp;rft.aulast=Bernad%C3%B3&amp;rft.aufirst=Ester&amp;rft.au=Llor%C3%A0%2C+Xavier&amp;rft.au=Garrell%2C+Josep+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><cite class="citation book">Bacardit, Jaume; Butz, Martin V. (2007-01-01).  Kovacs, Tim; Llorà, Xavier; Takadama, Keiki; Lanzi, Pier Luca; Stolzmann, Wolfgang; Wilson, Stewart W. (eds.). <i>Learning Classifier Systems</i>. Lecture Notes in Computer Science. Springer Berlin Heidelberg. pp.&#160;282–290. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.553.4679">10.1.1.553.4679</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-540-71231-2_19">10.1007/978-3-540-71231-2_19</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9783540712305" title="Special:BookSources/9783540712305"><bdi>9783540712305</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Learning+Classifier+Systems&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=282-290&amp;rft.pub=Springer+Berlin+Heidelberg&amp;rft.date=2007-01-01&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.553.4679&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-540-71231-2_19&amp;rft.isbn=9783540712305&amp;rft.aulast=Bacardit&amp;rft.aufirst=Jaume&amp;rft.au=Butz%2C+Martin+V.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation book">Urbanowicz, Ryan; Ramanand, Niranjan; Moore, Jason (2015-01-01). <i>Continuous Endpoint Data Mining with ExSTraCS: A Supervised Learning Classifier System</i>. <i>Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation</i>. GECCO Companion '15. New York, NY, USA: ACM. pp.&#160;1029–1036. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F2739482.2768453">10.1145/2739482.2768453</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9781450334884" title="Special:BookSources/9781450334884"><bdi>9781450334884</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Continuous+Endpoint+Data+Mining+with+ExSTraCS%3A+A+Supervised+Learning+Classifier+System&amp;rft.place=New+York%2C+NY%2C+USA&amp;rft.series=GECCO+Companion+%2715&amp;rft.pages=1029-1036&amp;rft.pub=ACM&amp;rft.date=2015-01-01&amp;rft_id=info%3Adoi%2F10.1145%2F2739482.2768453&amp;rft.isbn=9781450334884&amp;rft.aulast=Urbanowicz&amp;rft.aufirst=Ryan&amp;rft.au=Ramanand%2C+Niranjan&amp;rft.au=Moore%2C+Jason&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation journal">Butz, M. V.; Lanzi, P. L.; Wilson, S. W. (2008-06-01). "Function Approximation With XCS: Hyperellipsoidal Conditions, Recursive Least Squares, and Compaction". <i>IEEE Transactions on Evolutionary Computation</i>. <b>12</b> (3): 355–376. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FTEVC.2007.903551">10.1109/TEVC.2007.903551</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1089-778X">1089-778X</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Evolutionary+Computation&amp;rft.atitle=Function+Approximation+With+XCS%3A+Hyperellipsoidal+Conditions%2C+Recursive+Least+Squares%2C+and+Compaction&amp;rft.volume=12&amp;rft.issue=3&amp;rft.pages=355-376&amp;rft.date=2008-06-01&amp;rft_id=info%3Adoi%2F10.1109%2FTEVC.2007.903551&amp;rft.issn=1089-778X&amp;rft.aulast=Butz&amp;rft.aufirst=M.+V.&amp;rft.au=Lanzi%2C+P.+L.&amp;rft.au=Wilson%2C+S.+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://ryanurbanowicz.com/wp-content/uploads/2016/09/Urbanowicz_Browne_2015_Introducing-Rule-Based-Machine-Learning-A-Practical-Guide-GECCO15-CRC-Copy.pdf">Introducing Rule-Based Machine Learning:  A Practical Guide</a>, Ryan J. Urbanowicz and Will Browne, see pp. 72-73 for Michigan-style architecture vs. Pittsburgh-style architecture.</span>
</li>
<li id="cite_note-:10-11"><span class="mw-cite-backlink">^ <a href="#cite_ref-:10_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:10_11-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:10_11-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Wilson, Stewart W. (1995-06-01). "Classifier Fitness Based on Accuracy". <i>Evol. Comput</i>. <b>3</b> (2): 149–175. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.363.2210">10.1.1.363.2210</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fevco.1995.3.2.149">10.1162/evco.1995.3.2.149</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1063-6560">1063-6560</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Evol.+Comput.&amp;rft.atitle=Classifier+Fitness+Based+on+Accuracy&amp;rft.volume=3&amp;rft.issue=2&amp;rft.pages=149-175&amp;rft.date=1995-06-01&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.363.2210&amp;rft.issn=1063-6560&amp;rft_id=info%3Adoi%2F10.1162%2Fevco.1995.3.2.149&amp;rft.aulast=Wilson&amp;rft.aufirst=Stewart+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-:11-12"><span class="mw-cite-backlink">^ <a href="#cite_ref-:11_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:11_12-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:11_12-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Urbanowicz, R. J.; Granizo-Mackenzie, A.; Moore, J. H. (2012-11-01). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4244006">"An analysis pipeline with statistical and visualization-guided knowledge discovery for Michigan-style learning classifier systems"</a>. <i>IEEE Computational Intelligence Magazine</i>. <b>7</b> (4): 35–45. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FMCI.2012.2215124">10.1109/MCI.2012.2215124</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1556-603X">1556-603X</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4244006">4244006</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/25431544">25431544</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Computational+Intelligence+Magazine&amp;rft.atitle=An+analysis+pipeline+with+statistical+and+visualization-guided+knowledge+discovery+for+Michigan-style+learning+classifier+systems&amp;rft.volume=7&amp;rft.issue=4&amp;rft.pages=35-45&amp;rft.date=2012-11-01&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4244006&amp;rft.issn=1556-603X&amp;rft_id=info%3Apmid%2F25431544&amp;rft_id=info%3Adoi%2F10.1109%2FMCI.2012.2215124&amp;rft.aulast=Urbanowicz&amp;rft.aufirst=R.+J.&amp;rft.au=Granizo-Mackenzie%2C+A.&amp;rft.au=Moore%2C+J.+H.&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4244006&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-:12-13"><span class="mw-cite-backlink">^ <a href="#cite_ref-:12_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:12_13-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Bacardit, Jaume; Llorà, Xavier (2013). "Large‐scale data mining using genetics‐based machine learning". <i>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</i>. <b>3</b> (1): 37–61. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1002%2Fwidm.1078">10.1002/widm.1078</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wiley+Interdisciplinary+Reviews%3A+Data+Mining+and+Knowledge+Discovery&amp;rft.atitle=Large%E2%80%90scale+data+mining+using+genetics%E2%80%90based+machine+learning&amp;rft.volume=3&amp;rft.issue=1&amp;rft.pages=37-61&amp;rft.date=2013&amp;rft_id=info%3Adoi%2F10.1002%2Fwidm.1078&amp;rft.aulast=Bacardit&amp;rft.aufirst=Jaume&amp;rft.au=Llor%C3%A0%2C+Xavier&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation book">Holland, John (1975). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=5EgGaBkwvWcC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false"><i>Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence</i></a>. Michigan Press. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9780262581110" title="Special:BookSources/9780262581110"><bdi>9780262581110</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Adaptation+in+natural+and+artificial+systems%3A+an+introductory+analysis+with+applications+to+biology%2C+control%2C+and+artificial+intelligence&amp;rft.pub=Michigan+Press&amp;rft.date=1975&amp;rft.isbn=9780262581110&amp;rft.aulast=Holland&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D5EgGaBkwvWcC%26printsec%3Dfrontcover%23v%3Donepage%26q%26f%3Dfalse&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text">Holland JH (1976) Adaptation. In: Rosen R, Snell F (eds) Progress in theoretical biology, vol 4. Academic Press, New York, pp 263–293</span>
</li>
<li id="cite_note-:2-16"><span class="mw-cite-backlink">^ <a href="#cite_ref-:2_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:2_16-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Holland JH, Reitman JS (1978) Cognitive systems based on
adaptive algorithms Reprinted in: Evolutionary computation.
The fossil record. In: David BF (ed) IEEE Press, New York
1998. <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-7803-3481-7" title="Special:BookSources/0-7803-3481-7">0-7803-3481-7</a></span>
</li>
<li id="cite_note-:3-17"><span class="mw-cite-backlink">^ <a href="#cite_ref-:3_17-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:3_17-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Lanzi, Pier Luca (2008-02-08). "Learning classifier systems: then and now". <i>Evolutionary Intelligence</i>. <b>1</b> (1): 63–82. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs12065-007-0003-3">10.1007/s12065-007-0003-3</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1864-5909">1864-5909</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Evolutionary+Intelligence&amp;rft.atitle=Learning+classifier+systems%3A+then+and+now&amp;rft.volume=1&amp;rft.issue=1&amp;rft.pages=63-82&amp;rft.date=2008-02-08&amp;rft_id=info%3Adoi%2F10.1007%2Fs12065-007-0003-3&amp;rft.issn=1864-5909&amp;rft.aulast=Lanzi&amp;rft.aufirst=Pier+Luca&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text">Smith S (1980) A learning system based on genetic adaptive
algorithms. Ph.D. thesis, Department of Computer Science,
University of Pittsburgh</span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text">Smith S (1983) <a rel="nofollow" class="external text" href="https://www.researchgate.net/profile/Stephen_Smith14/publication/220815785_Flexible_Learning_of_Problem_Solving_Heuristics_Through_Adaptive_Search/links/0deec52c18dbd0dd53000000.pdf">Flexible learning of problem solving heuristics through adaptive search</a>. In: Eighth international joint conference
on articial intelligence. Morgan Kaufmann, Los Altos, pp
421–425</span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text">De Jong KA (1988) Learning with genetic algorithms: an overview. Mach Learn 3:121–138</span>
</li>
<li id="cite_note-:4-21"><span class="mw-cite-backlink">^ <a href="#cite_ref-:4_21-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:4_21-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:4_21-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=216016">Holland, John H. "Escaping brittleness: the possibilities of general purpose learning algorithms applied to parallel rule-based system." <i>Machine learning</i>(1986): 593-623.</a></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><cite class="citation book">Holland, John H. (1985-01-01). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=645511.657087"><i>Properties of the Bucket Brigade</i></a>. <i>Proceedings of the 1st International Conference on Genetic Algorithms</i>. Hillsdale, NJ, USA: L. Erlbaum Associates Inc. pp.&#160;1–7. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0805804263" title="Special:BookSources/978-0805804263"><bdi>978-0805804263</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Properties+of+the+Bucket+Brigade&amp;rft.place=Hillsdale%2C+NJ%2C+USA&amp;rft.pages=1-7&amp;rft.pub=L.+Erlbaum+Associates+Inc.&amp;rft.date=1985-01-01&amp;rft.isbn=978-0805804263&amp;rft.aulast=Holland&amp;rft.aufirst=John+H.&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D645511.657087&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation thesis">Booker, L (1982-01-01). <a rel="nofollow" class="external text" href="http://www.citeulike.org/group/664/article/431772"><i>Intelligent Behavior as a Adaptation to the Task Environment</i></a> (Thesis). University of Michigan.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Intelligent+Behavior+as+a+Adaptation+to+the+Task+Environment&amp;rft.inst=University+of+Michigan&amp;rft.date=1982-01-01&amp;rft.aulast=Booker&amp;rft.aufirst=L&amp;rft_id=http%3A%2F%2Fwww.citeulike.org%2Fgroup%2F664%2Farticle%2F431772&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-:5-24"><span class="mw-cite-backlink">^ <a href="#cite_ref-:5_24-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:5_24-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:5_24-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">Wilson, S. W. "<a rel="nofollow" class="external text" href="http://www.cs.sfu.ca/~vaughan/teaching/415/papers/wilson_animat.pdf">Knowledge growth in an artificial animal</a>. Proceedings of the First International Conference on Genetic Algorithms and their Applications." (1985).</span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation journal">Wilson, Stewart W. (1987). "Classifier systems and the animat problem". <i>Machine Learning</i>. <b>2</b> (3): 199–228. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1007%2FBF00058679">10.1007/BF00058679</a></span>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0885-6125">0885-6125</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Classifier+systems+and+the+animat+problem&amp;rft.volume=2&amp;rft.issue=3&amp;rft.pages=199-228&amp;rft.date=1987&amp;rft_id=info%3Adoi%2F10.1007%2FBF00058679&amp;rft.issn=0885-6125&amp;rft.aulast=Wilson&amp;rft.aufirst=Stewart+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation book">Bonelli, Pierre; Parodi, Alexandre; Sen, Sandip; Wilson, Stewart (1990-01-01). <span class="cs1-lock-registration" title="Free registration required"><a rel="nofollow" class="external text" href="https://archive.org/details/machinelearningp0000inte/page/153"><i>NEWBOOLE: A Fast GBML System</i></a></span>. <i>Proceedings of the Seventh International Conference (1990) on Machine Learning</i>. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc. pp.&#160;<a rel="nofollow" class="external text" href="https://archive.org/details/machinelearningp0000inte/page/153">153–159</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1558601413" title="Special:BookSources/978-1558601413"><bdi>978-1558601413</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=NEWBOOLE%3A+A+Fast+GBML+System&amp;rft.place=San+Francisco%2C+CA%2C+USA&amp;rft.pages=153-159&amp;rft.pub=Morgan+Kaufmann+Publishers+Inc.&amp;rft.date=1990-01-01&amp;rft.isbn=978-1558601413&amp;rft.aulast=Bonelli&amp;rft.aufirst=Pierre&amp;rft.au=Parodi%2C+Alexandre&amp;rft.au=Sen%2C+Sandip&amp;rft.au=Wilson%2C+Stewart&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fmachinelearningp0000inte%2Fpage%2F153&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation journal">Frey, Peter W.; Slate, David J. (1991). "Letter recognition using Holland-style adaptive classifiers". <i>Machine Learning</i>. <b>6</b> (2): 161–182. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1007%2FBF00114162">10.1007/BF00114162</a></span>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0885-6125">0885-6125</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Letter+recognition+using+Holland-style+adaptive+classifiers&amp;rft.volume=6&amp;rft.issue=2&amp;rft.pages=161-182&amp;rft.date=1991&amp;rft_id=info%3Adoi%2F10.1007%2FBF00114162&amp;rft.issn=0885-6125&amp;rft.aulast=Frey&amp;rft.aufirst=Peter+W.&amp;rft.au=Slate%2C+David+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text">Valenzuela-Rendón, Manuel. "<a rel="nofollow" class="external text" href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/GeneticFuzzySystems/(1991)_Valenzuela-Rendon.pdf">The Fuzzy Classifier System: A Classifier System for Continuously Varying Variables</a>." In <i>ICGA</i>, pp. 346-353. 1991.</span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><cite class="citation thesis">Riolo, Rick L. (1988-01-01). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=914945"><i>Empirical Studies of Default Hierarchies and Sequences of Rules in Learning Classifier Systems</i></a> (Thesis). Ann Arbor, MI, USA: University of Michigan.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Empirical+Studies+of+Default+Hierarchies+and+Sequences+of+Rules+in+Learning+Classifier+Systems&amp;rft.inst=University+of+Michigan&amp;rft.date=1988-01-01&amp;rft.aulast=Riolo&amp;rft.aufirst=Rick+L.&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D914945&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><cite class="citation journal">R.L., Riolo (1987-01-01). <a rel="nofollow" class="external text" href="http://agris.fao.org/agris-search/search.do?recordID=US201301782174">"Bucket brigade performance. I. Long sequences of classifiers"</a>. <i>Genetic Algorithms and Their Applications&#160;: Proceedings of the Second International Conference on Genetic Algorithms&#160;: July 28–31, 1987 at the Massachusetts Institute of Technology, Cambridge, MA</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Genetic+Algorithms+and+Their+Applications+%3A+Proceedings+of+the+Second+International+Conference+on+Genetic+Algorithms+%3A+July+28%E2%80%9331%2C+1987+at+the+Massachusetts+Institute+of+Technology%2C+Cambridge%2C+MA&amp;rft.atitle=Bucket+brigade+performance.+I.+Long+sequences+of+classifiers&amp;rft.date=1987-01-01&amp;rft.aulast=R.L.&amp;rft.aufirst=Riolo&amp;rft_id=http%3A%2F%2Fagris.fao.org%2Fagris-search%2Fsearch.do%3FrecordID%3DUS201301782174&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation journal">R.L., Riolo (1987-01-01). <a rel="nofollow" class="external text" href="http://agris.fao.org/agris-search/search.do?recordID=US201301782175">"Bucket brigade performance. II. Default hierarchies"</a>. <i>Genetic Algorithms and Their Applications&#160;: Proceedings of the Second International Conference on Genetic Algorithms&#160;: July 28–31, 1987 at the Massachusetts Institute of Technology, Cambridge, MA</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Genetic+Algorithms+and+Their+Applications+%3A+Proceedings+of+the+Second+International+Conference+on+Genetic+Algorithms+%3A+July+28%E2%80%9331%2C+1987+at+the+Massachusetts+Institute+of+Technology%2C+Cambridge%2C+MA&amp;rft.atitle=Bucket+brigade+performance.+II.+Default+hierarchies&amp;rft.date=1987-01-01&amp;rft.aulast=R.L.&amp;rft.aufirst=Riolo&amp;rft_id=http%3A%2F%2Fagris.fao.org%2Fagris-search%2Fsearch.do%3FrecordID%3DUS201301782175&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-:7-32"><span class="mw-cite-backlink">^ <a href="#cite_ref-:7_32-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:7_32-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">W. Stolzmann, "Anticipatory classifier systems," in Proceedings

of the 3rd Annual Genetic Programming Conference, pp.

658–664, 1998.</span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><cite class="citation book">Riolo, Rick L. (1990-01-01). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=116517.116553"><i>Lookahead Planning and Latent Learning in a Classifier System</i></a>. <i>Proceedings of the First International Conference on Simulation of Adaptive Behavior on from Animals to Animats</i>. Cambridge, MA, USA: MIT Press. pp.&#160;316–326. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0262631389" title="Special:BookSources/978-0262631389"><bdi>978-0262631389</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Lookahead+Planning+and+Latent+Learning+in+a+Classifier+System&amp;rft.place=Cambridge%2C+MA%2C+USA&amp;rft.pages=316-326&amp;rft.pub=MIT+Press&amp;rft.date=1990-01-01&amp;rft.isbn=978-0262631389&amp;rft.aulast=Riolo&amp;rft.aufirst=Rick+L.&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D116517.116553&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text">Watkins, Christopher John Cornish Hellaby. "Learning from delayed rewards." PhD diss., University of Cambridge, 1989.</span>
</li>
<li id="cite_note-:6-35"><span class="mw-cite-backlink">^ <a href="#cite_ref-:6_35-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:6_35-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Wilson, Stewart W. (1994-03-01). "ZCS: A Zeroth Level Classifier System". <i>Evolutionary Computation</i>. <b>2</b> (1): 1–18. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.363.798">10.1.1.363.798</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fevco.1994.2.1.1">10.1162/evco.1994.2.1.1</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1063-6560">1063-6560</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Evolutionary+Computation&amp;rft.atitle=ZCS%3A+A+Zeroth+Level+Classifier+System&amp;rft.volume=2&amp;rft.issue=1&amp;rft.pages=1-18&amp;rft.date=1994-03-01&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.363.798&amp;rft.issn=1063-6560&amp;rft_id=info%3Adoi%2F10.1162%2Fevco.1994.2.1.1&amp;rft.aulast=Wilson&amp;rft.aufirst=Stewart+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><cite class="citation journal">Lanzi, P. L. (2002). "Learning classifier systems from a reinforcement learning perspective". <i>Soft Computing</i>. <b>6</b> (3–4): 162–170. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs005000100113">10.1007/s005000100113</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1432-7643">1432-7643</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Soft+Computing&amp;rft.atitle=Learning+classifier+systems+from+a+reinforcement+learning+perspective&amp;rft.volume=6&amp;rft.issue=3%E2%80%934&amp;rft.pages=162-170&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1007%2Fs005000100113&amp;rft.issn=1432-7643&amp;rft.aulast=Lanzi&amp;rft.aufirst=P.+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text">Kovacs, Timothy Michael Douglas. <i>A Comparison of Strength and Accuracy-based Fitness in Learning and Classifier Systems</i>. 2002.</span>
</li>
<li id="cite_note-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-38">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://link.springer.com/chapter/10.1007/3-540-48104-4_6">Kovacs, Tim. "Two views of classifier systems." In <i>International Workshop on Learning Classifier Systems</i>, pp. 74-87. Springer Berlin Heidelberg, 2001</a></span>
</li>
<li id="cite_note-:8-39"><span class="mw-cite-backlink">^ <a href="#cite_ref-:8_39-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:8_39-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Congdon, Clare Bates. "A comparison of genetic algorithms and other machine learning systems on a complex classification task from common disease research." PhD diss., The University of Michigan, 1995.</span>
</li>
<li id="cite_note-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-40">^</a></b></span> <span class="reference-text"><cite class="citation journal">Holmes, John H. (1996-01-01). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2233061">"A Genetics-Based Machine Learning Approach to Knowledge Discovery in Clinical Data"</a>. <i>Proceedings of the AMIA Annual Fall Symposium</i>: 883. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1091-8280">1091-8280</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2233061">2233061</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+AMIA+Annual+Fall+Symposium&amp;rft.atitle=A+Genetics-Based+Machine+Learning+Approach+to+Knowledge+Discovery+in+Clinical+Data&amp;rft.pages=883&amp;rft.date=1996-01-01&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2233061&amp;rft.issn=1091-8280&amp;rft.aulast=Holmes&amp;rft.aufirst=John+H.&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2233061&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-41">^</a></b></span> <span class="reference-text">Holmes, John H. "<a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/71e4/eb6c630dee4b762e74b2970f6dc638a351ab.pdf">Discovering Risk of Disease with a Learning Classifier System</a>." In <i>ICGA</i>, pp. 426-433. 1997.</span>
</li>
<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-42">^</a></b></span> <span class="reference-text">Holmes, John H., and Jennifer A. Sager. "<a rel="nofollow" class="external text" href="https://link.springer.com/10.1007%2F11527770_60">Rule discovery in epidemiologic surveillance data using EpiXCS: an evolutionary computation approach</a>." In<i>Conference on Artificial Intelligence in Medicine in Europe</i>, pp. 444-452. Springer Berlin Heidelberg, 2005.</span>
</li>
<li id="cite_note-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-43">^</a></b></span> <span class="reference-text">Butz, Martin V. "<a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/3572/7a56fcce7a73ccc43e5bfa19389780e6d436.pdf">Biasing exploration in an anticipatory learning classifier system</a>." In <i>International Workshop on Learning Classifier Systems</i>, pp. 3-22. Springer Berlin Heidelberg, 2001.</span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44">^</a></b></span> <span class="reference-text"><cite class="citation journal">Wilson, Stewart W. (2002). "Classifiers that approximate functions". <i>Natural Computing</i>. <b>1</b> (2–3): 211–234. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1023%2FA%3A1016535925043">10.1023/A:1016535925043</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1567-7818">1567-7818</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Natural+Computing&amp;rft.atitle=Classifiers+that+approximate+functions&amp;rft.volume=1&amp;rft.issue=2%E2%80%933&amp;rft.pages=211-234&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1016535925043&amp;rft.issn=1567-7818&amp;rft.aulast=Wilson&amp;rft.aufirst=Stewart+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-45">^</a></b></span> <span class="reference-text">Bull, Larry. "<a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/120c/8f5057995c36ee60ec320c2263b20af05444.pdf">A simple accuracy-based learning classifier system</a>." <i>Learning Classifier Systems Group Technical Report UWELCSG03-005, University of the West of England, Bristol, UK</i> (2003).</span>
</li>
<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-46">^</a></b></span> <span class="reference-text">Bull, Larry. "<a rel="nofollow" class="external text" href="https://link.springer.com/chapter/10.1007/978-3-540-30217-9_104">A simple payoff-based learning classifier system</a>." In<i>International Conference on Parallel Problem Solving from Nature</i>, pp. 1032-1041. Springer Berlin Heidelberg, 2004.</span>
</li>
<li id="cite_note-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-47">^</a></b></span> <span class="reference-text">Peñarroya, Jaume Bacardit. "Pittsburgh genetic-based machine learning in the data mining era: representations, generalization, and run-time." PhD diss., Universitat Ramon Llull, 2004.</span>
</li>
<li id="cite_note-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-48">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bacardit, Jaume; Burke, Edmund K.; Krasnogor, Natalio (2008-12-12). "Improving the scalability of rule-based evolutionary learning". <i>Memetic Computing</i>. <b>1</b> (1): 55–67. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs12293-008-0005-4">10.1007/s12293-008-0005-4</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1865-9284">1865-9284</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Memetic+Computing&amp;rft.atitle=Improving+the+scalability+of+rule-based+evolutionary+learning&amp;rft.volume=1&amp;rft.issue=1&amp;rft.pages=55-67&amp;rft.date=2008-12-12&amp;rft_id=info%3Adoi%2F10.1007%2Fs12293-008-0005-4&amp;rft.issn=1865-9284&amp;rft.aulast=Bacardit&amp;rft.aufirst=Jaume&amp;rft.au=Burke%2C+Edmund+K.&amp;rft.au=Krasnogor%2C+Natalio&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-49">^</a></b></span> <span class="reference-text"><cite class="citation book">Drugowitsch, Jan (2008). <i>Design and Analysis of Learning Classifier Systems - Springer</i>. Studies in Computational Intelligence. <b>139</b>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-540-79866-8">10.1007/978-3-540-79866-8</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-79865-1" title="Special:BookSources/978-3-540-79865-1"><bdi>978-3-540-79865-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Design+and+Analysis+of+Learning+Classifier+Systems+-+Springer&amp;rft.series=Studies+in+Computational+Intelligence&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-540-79866-8&amp;rft.isbn=978-3-540-79865-1&amp;rft.aulast=Drugowitsch&amp;rft.aufirst=Jan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-50">^</a></b></span> <span class="reference-text">Urbanowicz, Ryan J., Gediminas Bertasius, and Jason H. Moore. "<a rel="nofollow" class="external text" href="http://www.seas.upenn.edu/~gberta/uploads/3/1/4/8/31486883/urbanowicz_2014_exstracs_algorithm.pdf">An extended michigan-style learning classifier system for flexible supervised learning, classification, and data mining</a>." In <i>International Conference on Parallel Problem Solving from Nature</i>, pp. 211-221. Springer International Publishing, 2014.</span>
</li>
<li id="cite_note-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-51">^</a></b></span> <span class="reference-text">Urbanowicz, Ryan J., Delaney Granizo-Mackenzie, and Jason H. Moore. "<a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/b407/8f8bb6aa9e39e84b0b20874662a6ed8b7df1.pdf">Using expert knowledge to guide covering and mutation in a michigan style learning classifier system to detect epistasis and heterogeneity</a>." In<i>International Conference on Parallel Problem Solving from Nature</i>, pp. 266-275. Springer Berlin Heidelberg, 2012.</span>
</li>
<li id="cite_note-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-52">^</a></b></span> <span class="reference-text"><cite class="citation book">Urbanowicz, Ryan; Granizo-Mackenzie, Ambrose; Moore, Jason (2012-01-01). <i>Instance-linked Attribute Tracking and Feedback for Michigan-style Supervised Learning Classifier Systems</i>. <i>Proceedings of the 14th Annual Conference on Genetic and Evolutionary Computation</i>. GECCO '12. New York, NY, USA: ACM. pp.&#160;927–934. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F2330163.2330291">10.1145/2330163.2330291</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9781450311779" title="Special:BookSources/9781450311779"><bdi>9781450311779</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Instance-linked+Attribute+Tracking+and+Feedback+for+Michigan-style+Supervised+Learning+Classifier+Systems&amp;rft.place=New+York%2C+NY%2C+USA&amp;rft.series=GECCO+%2712&amp;rft.pages=927-934&amp;rft.pub=ACM&amp;rft.date=2012-01-01&amp;rft_id=info%3Adoi%2F10.1145%2F2330163.2330291&amp;rft.isbn=9781450311779&amp;rft.aulast=Urbanowicz&amp;rft.aufirst=Ryan&amp;rft.au=Granizo-Mackenzie%2C+Ambrose&amp;rft.au=Moore%2C+Jason&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-53">^</a></b></span> <span class="reference-text"><cite class="citation book">Bacardit, Jaume; Krasnogor, Natalio (2009-01-01). <i>A Mixed Discrete-continuous Attribute List Representation for Large Scale Classification Domains</i>. <i>Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation</i>. GECCO '09. New York, NY, USA: ACM. pp.&#160;1155–1162. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.158.7314">10.1.1.158.7314</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F1569901.1570057">10.1145/1569901.1570057</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9781605583259" title="Special:BookSources/9781605583259"><bdi>9781605583259</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+Mixed+Discrete-continuous+Attribute+List+Representation+for+Large+Scale+Classification+Domains&amp;rft.place=New+York%2C+NY%2C+USA&amp;rft.series=GECCO+%2709&amp;rft.pages=1155-1162&amp;rft.pub=ACM&amp;rft.date=2009-01-01&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.158.7314&amp;rft_id=info%3Adoi%2F10.1145%2F1569901.1570057&amp;rft.isbn=9781605583259&amp;rft.aulast=Bacardit&amp;rft.aufirst=Jaume&amp;rft.au=Krasnogor%2C+Natalio&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-54">^</a></b></span> <span class="reference-text"><cite class="citation journal">Iqbal, Muhammad; Browne, Will N.; Zhang, Mengjie (2014-08-01). "Reusing Building Blocks of Extracted Knowledge to Solve Complex, Large-Scale Boolean Problems". <i>IEEE Transactions on Evolutionary Computation</i>. <b>18</b> (4): 465–480. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ftevc.2013.2281537">10.1109/tevc.2013.2281537</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Evolutionary+Computation&amp;rft.atitle=Reusing+Building+Blocks+of+Extracted+Knowledge+to+Solve+Complex%2C+Large-Scale+Boolean+Problems&amp;rft.volume=18&amp;rft.issue=4&amp;rft.pages=465-480&amp;rft.date=2014-08-01&amp;rft_id=info%3Adoi%2F10.1109%2Ftevc.2013.2281537&amp;rft.aulast=Iqbal&amp;rft.aufirst=Muhammad&amp;rft.au=Browne%2C+Will+N.&amp;rft.au=Zhang%2C+Mengjie&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-55">^</a></b></span> <span class="reference-text"><cite class="citation journal">Booker, L. B.; Goldberg, D. E.; Holland, J. H. (1989-09-01). <a rel="nofollow" class="external text" href="https://deepblue.lib.umich.edu/bitstream/2027.42/27777/1/0000171.pdf">"Classifier systems and genetic algorithms"</a> <span class="cs1-format">(PDF)</span>. <i>Artificial Intelligence</i>. <b>40</b> (1): 235–282. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2F0004-3702%2889%2990050-7">10.1016/0004-3702(89)90050-7</a>. <a href="/wiki/Handle_System" title="Handle System">hdl</a>:<a rel="nofollow" class="external text" href="//hdl.handle.net/2027.42%2F27777">2027.42/27777</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence&amp;rft.atitle=Classifier+systems+and+genetic+algorithms&amp;rft.volume=40&amp;rft.issue=1&amp;rft.pages=235-282&amp;rft.date=1989-09-01&amp;rft_id=info%3Ahdl%2F2027.42%2F27777&amp;rft_id=info%3Adoi%2F10.1016%2F0004-3702%2889%2990050-7&amp;rft.aulast=Booker&amp;rft.aufirst=L.+B.&amp;rft.au=Goldberg%2C+D.+E.&amp;rft.au=Holland%2C+J.+H.&amp;rft_id=https%3A%2F%2Fdeepblue.lib.umich.edu%2Fbitstream%2F2027.42%2F27777%2F1%2F0000171.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALearning+classifier+system" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r935243608"/></span>
</li>
<li id="cite_note-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-56">^</a></b></span> <span class="reference-text">Wilson, Stewart W., and David E. Goldberg. "A critical review of classifier systems." In <i>Proceedings of the third international conference on Genetic algorithms</i>, pp. 244-255. Morgan Kaufmann Publishers Inc., 1989.</span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=29" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Video_tutorial">Video tutorial</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=30" title="Edit section: Video tutorial">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=CRge_cZ2cJc">Learning Classifier Systems in a Nutshell</a> - (2016) Go inside a basic LCS algorithm to learn their components and how they work.</li></ul>
<h3><span class="mw-headline" id="Webpages">Webpages</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit&amp;section=31" title="Edit section: Webpages">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li><a rel="nofollow" class="external text" href="http://gbml.org/">LCS &amp; GBML Central</a></li>
<li><a rel="nofollow" class="external text" href="http://www.cems.uwe.ac.uk/lcsg/">UWE Learning Classifier Research Group</a></li>
<li><a rel="nofollow" class="external text" href="http://prediction-dynamics.com/">Prediction Dynamics</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw1363
Cached time: 20200415225016
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.484 seconds
Real time usage: 0.580 seconds
Preprocessor visited node count: 2335/1000000
Post‐expand include size: 71028/2097152 bytes
Template argument size: 624/2097152 bytes
Highest expansion depth: 15/40
Expensive parser function count: 5/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 130141/5000000 bytes
Number of Wikibase entities loaded: 5/400
Lua time usage: 0.290/10.000 seconds
Lua memory usage: 4.73 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  468.782      1 Template:Reflist
100.00%  468.782      1 -total
 62.46%  292.805     21 Template:Cite_journal
 13.60%   63.764     10 Template:Cite_book
 12.80%   59.984      1 Template:ISBN
  4.18%   19.577      1 Template:Error-small
  3.61%   16.942      1 Template:Catalog_lookup_link
  2.05%    9.615      2 Template:Cite_thesis
  2.03%    9.531      1 Template:Small
  1.18%    5.513      3 Template:Yesno-no
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:854461-0!canonical and timestamp 20200415225016 and revision id 951186345
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Learning_classifier_system&amp;oldid=951186345">https://en.wikipedia.org/w/index.php?title=Learning_classifier_system&amp;oldid=951186345</a>"</div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Evolutionary_algorithms" title="Category:Evolutionary algorithms">Evolutionary algorithms</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
    <h2>Navigation menu</h2>
    <div id="mw-head">
        
        <div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
        	<h3 id="p-personal-label">Personal tools</h3>
        	<ul >
        		
        		<li id="pt-anonuserpage">Not logged in</li>
        		<li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Learning+classifier+system" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Learning+classifier+system" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>
        	</ul>
        </div>
        <div id="left-navigation">
            <div id="p-namespaces" role="navigation" class="vectorTabs " aria-labelledby="p-namespaces-label">
            	<h3 id="p-namespaces-label">Namespaces</h3>
            	<ul >
            		<li id="ca-nstab-main" class="selected"><a href="/wiki/Learning_classifier_system" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Learning_classifier_system" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t">Talk</a></li>
            	</ul>
            </div>
            <div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
            	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
            	<h3 id="p-variants-label">
            		<span>Variants</span>
            	</h3>
            	<ul class="menu" >
            		
            	</ul>
            </div>
        </div>
        <div id="right-navigation">
            <div id="p-views" role="navigation" class="vectorTabs " aria-labelledby="p-views-label">
            	<h3 id="p-views-label">Views</h3>
            	<ul >
            		<li id="ca-view" class="collapsible selected"><a href="/wiki/Learning_classifier_system">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Learning_classifier_system&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Learning_classifier_system&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>
            	</ul>
            </div>
            <div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
            	<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
            	<h3 id="p-cactions-label">
            		<span>More</span>
            	</h3>
            	<ul class="menu" >
            		
            	</ul>
            </div>
            <div id="p-search" role="search">
            	<h3 >
            		<label for="searchInput">Search</label>
            	</h3>
            	<form action="/w/index.php" id="searchform">
            		<div id="simpleSearch">
            			<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>
            			<input type="hidden" value="Special:Search" name="title"/>
            			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>
            			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>
            		</div>
            	</form>
            </div>
        </div>
    </div>
    
    <div id="mw-panel">
    	<div id="p-logo" role="banner">
    		<a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>
    	</div>
    	<div class="portal" role="navigation" id="p-navigation"  aria-labelledby="p-navigation-label">
    		<h3  id="p-navigation-label">
    			Navigation
    		</h3>
    		<div class="body">
    			<ul><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-interaction"  aria-labelledby="p-interaction-label">
    		<h3  id="p-interaction-label">
    			Interaction
    		</h3>
    		<div class="body">
    			<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-tb"  aria-labelledby="p-tb-label">
    		<h3  id="p-tb-label">
    			Tools
    		</h3>
    		<div class="body">
    			<ul><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Learning_classifier_system" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Learning_classifier_system" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Learning_classifier_system&amp;oldid=951186345" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Learning_classifier_system&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q3509276" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Learning_classifier_system&amp;id=951186345&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-coll-print_export"  aria-labelledby="p-coll-print_export-label">
    		<h3  id="p-coll-print_export-label">
    			Print/export
    		</h3>
    		<div class="body">
    			<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Learning+classifier+system">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Learning+classifier+system&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Learning_classifier_system&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>
    			
    		</div>
    	</div>
    	
    	<div class="portal" role="navigation" id="p-lang"  aria-labelledby="p-lang-label">
    		<h3  id="p-lang-label">
    			Languages
    		</h3>
    		<div class="body">
    			<ul><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Learning_Classifier_System" title="Learning Classifier System – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Syst%C3%A8me_de_classeurs" title="Système de classeurs – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li></ul>
    			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q3509276#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
    		</div>
    	</div>
    	
    </div>
</div>

<div id="footer" role="contentinfo" >
	<ul id="footer-info" class="">
		<li id="footer-info-lastmod"> This page was last edited on 15 April 2020, at 22:50<span class="anonymous-show">&#160;(UTC)</span>.</li>
		<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
	</ul>
	<ul id="footer-places" class="">
		<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
		<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
		<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
		<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
		<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
		<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Learning_classifier_system&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a></li>
		<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a></li>
	</ul>
	<div style="clear: both;"></div>
</div>

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.484","walltime":"0.580","ppvisitednodes":{"value":2335,"limit":1000000},"postexpandincludesize":{"value":71028,"limit":2097152},"templateargumentsize":{"value":624,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":5,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":130141,"limit":5000000},"entityaccesscount":{"value":5,"limit":400},"timingprofile":["100.00%  468.782      1 Template:Reflist","100.00%  468.782      1 -total"," 62.46%  292.805     21 Template:Cite_journal"," 13.60%   63.764     10 Template:Cite_book"," 12.80%   59.984      1 Template:ISBN","  4.18%   19.577      1 Template:Error-small","  3.61%   16.942      1 Template:Catalog_lookup_link","  2.05%    9.615      2 Template:Cite_thesis","  2.03%    9.531      1 Template:Small","  1.18%    5.513      3 Template:Yesno-no"]},"scribunto":{"limitreport-timeusage":{"value":"0.290","limit":"10.000"},"limitreport-memusage":{"value":4954790,"limit":52428800}},"cachereport":{"origin":"mw1363","timestamp":"20200415225016","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Learning classifier system","url":"https:\/\/en.wikipedia.org\/wiki\/Learning_classifier_system","sameAs":"http:\/\/www.wikidata.org\/entity\/Q3509276","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q3509276","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2004-07-24T14:34:14Z","dateModified":"2020-04-15T22:50:16Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/5\/5f\/Function_approximation_with_LCS_rules.jpg"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":113,"wgHostname":"mw1275"});});</script></body></html>
